#!/usr/bin/env python3
"""
–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞ —Å embeddings
–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è query –≤ embeddings
"""

import asyncio
import logging
from pathlib import Path
import sys

# –î–æ–±–∞–≤–ª—è–µ–º src –≤ –ø—É—Ç—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from rag_client import RAGClient

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

async def demonstrate_semantic_search():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞"""
    
    async with RAGClient() as client:
        
        # –¢–µ—Å—Ç–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞
        test_queries = [
            {
                "query": "–º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ",
                "description": "–ü—Ä—è–º–æ–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ —Ç–µ—Ä–º–∏–Ω–∞"
            },
            {
                "query": "ML algorithms neural networks",
                "description": "–ê–Ω–≥–ª–∏–π—Å–∫–∏–µ —Å–∏–Ω–æ–Ω–∏–º—ã"
            },
            {
                "query": "–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏",
                "description": "–°–º–µ–∂–Ω—ã–µ —Ç–µ—Ä–º–∏–Ω—ã"
            },
            {
                "query": "–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –¥–∞–Ω–Ω—ã—Ö",
                "description": "–û–ø–∏—Å–∞—Ç–µ–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å"
            },
            {
                "query": "–≤–µ–∫—Ç–æ—Ä–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞",
                "description": "–¢–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ embeddings"
            }
        ]
        
        logger.info("=== –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø –°–ï–ú–ê–ù–¢–ò–ß–ï–°–ö–û–ì–û –ü–û–ò–°–ö–ê ===")
        logger.info("–ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–∞–∫ query –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç—Å—è –≤ embeddings –∏ –∏—â–µ—Ç—Å—è –ø–æ similarity\n")
        
        for i, test_case in enumerate(test_queries, 1):
            query = test_case["query"]
            description = test_case["description"]
            
            logger.info(f"üîç –ó–∞–ø—Ä–æ—Å {i}: '{query}'")
            logger.info(f"   –¢–∏–ø: {description}")
            
            try:
                # –ü–æ–∏—Å–∫ —Å —Ä–∞–∑–Ω—ã–º–∏ –ø–æ—Ä–æ–≥–∞–º–∏ similarity
                thresholds = [0.8, 0.6, 0.4]
                
                for threshold in thresholds:
                    logger.info(f"   ‚îî‚îÄ –ü–æ—Ä–æ–≥ similarity: {threshold}")
                    
                    results = await client.semantic_search(
                        query=query,
                        top_k=3,
                        similarity_threshold=threshold,
                        rag_server_url="http://localhost:8000"
                    )
                    
                    if results:
                        logger.info(f"      –ù–∞–π–¥–µ–Ω–æ: {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
                        for j, result in enumerate(results[:2], 1):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ø-2
                            logger.info(f"      {j}. {result['file_name']} (similarity: {result['similarity']})")
                            logger.info(f"         –ü—Ä–µ–≤—å—é: {result['content'][:100]}...")
                    else:
                        logger.info(f"      –†–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
                
                logger.info("")  # –ü—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
                
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –¥–ª—è '{query}': {e}")

async def demonstrate_embedding_importance():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –≤–∞–∂–Ω–æ—Å—Ç–∏ embeddings"""
    
    logger.info("=== –ü–û–ß–ï–ú–£ EMBEDDINGS –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–´ ===\n")
    
    # –û–±—ä—è—Å–Ω—è–µ–º –ø—Ä–æ—Ü–µ—Å—Å
    explanations = [
        "1. üìÑ –ü—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:",
        "   - –¢–µ–∫—Å—Ç —Ä–∞–∑–±–∏–≤–∞–µ—Ç—Å—è –Ω–∞ chunks",
        "   - –ö–∞–∂–¥—ã–π chunk ‚Üí model.encode() ‚Üí embedding FLOAT[768]", 
        "   - Embeddings —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤ DuckDB",
        "",
        "2. üîç –ü—Ä–∏ –ø–æ–∏—Å–∫–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:",
        "   - –ó–∞–ø—Ä–æ—Å '–º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ' ‚Üí model.encode() ‚Üí query_embedding",
        "   - DuckDB: array_cosine_similarity(chunk_embedding, query_embedding)",
        "   - –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ä—Ç–∏—Ä—É—é—Ç—Å—è –ø–æ similarity DESC",
        "",
        "3. üéØ –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–µ –ø–æ–Ω–∏–º–∞–Ω–∏–µ:",
        "   - '–º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ' ‚âà 'ML' ‚âà 'neural networks'",
        "   - Embeddings –∫–æ–¥–∏—Ä—É—é—Ç —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π —Å–º—ã—Å–ª, –Ω–µ —Ç–æ–ª—å–∫–æ —Å–ª–æ–≤–∞",
        "   - –û–¥–Ω–∞ –º–æ–¥–µ–ª—å –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏ –∑–∞–ø—Ä–æ—Å–æ–≤ ‚Üí –µ–¥–∏–Ω–æ–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ",
        "",
        "4. ‚ùå –ë–µ–∑ embeddings –∑–∞–ø—Ä–æ—Å–∞:",
        "   - –ù–µ–≤–æ–∑–º–æ–∂–Ω–æ —Å—Ä–∞–≤–Ω–∏—Ç—å text —Å FLOAT[768]",
        "   - –ù–µ—Ç —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è",
        "   - –¢–æ–ª—å–∫–æ —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å–ª–æ–≤ (–∫–∞–∫ grep)",
        "",
        "5. ‚úÖ –° embeddings:",
        "   - –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –ø–æ —Å–º—ã—Å–ª—É",
        "   - –ù–∞—Ö–æ–¥–∏—Ç —Å–∏–Ω–æ–Ω–∏–º—ã –∏ –±–ª–∏–∑–∫–∏–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏", 
        "   - –†–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —è–∑—ã–∫–∞—Ö",
        "   - Similarity score –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å"
    ]
    
    for explanation in explanations:
        logger.info(explanation)

async def demonstrate_similarity_thresholds():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –ø–æ—Ä–æ–≥–æ–≤ similarity"""
    
    logger.info("\n=== –ü–û–†–û–ì–ò SIMILARITY (–∏–∑ user_rule.txt) ===\n")
    
    thresholds = [
        {"range": "0.9 - 1.0", "interpretation": "–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –∏–¥–µ–Ω—Ç–∏—á–Ω—ã–π", "use_case": "–î–µ—Ç–µ–∫—Ü–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤"},
        {"range": "0.8 - 0.9", "interpretation": "–û—á–µ–Ω—å –ø–æ—Ö–æ–∂–∏–π", "use_case": "–ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"},
        {"range": "0.7 - 0.8", "interpretation": "–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏ —Å–≤—è–∑–∞–Ω–Ω—ã–π", "use_case": "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏"},
        {"range": "0.6 - 0.7", "interpretation": "–£–º–µ—Ä–µ–Ω–Ω–æ —Å–≤—è–∑–∞–Ω–Ω—ã–π", "use_case": "–†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –ø–æ–∏—Å–∫"},
        {"range": "0.5 - 0.6", "interpretation": "–°–ª–∞–±–∞—è —Å–≤—è–∑—å", "use_case": "–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è"},
        {"range": "0.3 - 0.5", "interpretation": "–û—á–µ–Ω—å —Å–ª–∞–±–∞—è —Å–≤—è–∑—å", "use_case": "‚Äî"},
        {"range": "0.0 - 0.3", "interpretation": "–ù–µ—Å–≤—è–∑–∞–Ω–Ω—ã–π", "use_case": "‚Äî"},
    ]
    
    logger.info("–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è similarity scores:")
    for threshold in thresholds:
        logger.info(f"  {threshold['range']}: {threshold['interpretation']} ({threshold['use_case']})")

async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    logger.info("üöÄ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞ —Å embeddings\n")
    
    try:
        # –û–±—ä—è—Å–Ω—è–µ–º —Ç–µ–æ—Ä–∏—é
        await demonstrate_embedding_importance()
        await demonstrate_similarity_thresholds()
        
        # –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∞—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è (–µ—Å–ª–∏ RAG —Å–µ—Ä–≤–µ—Ä –¥–æ—Å—Ç—É–ø–µ–Ω)
        try:
            await demonstrate_semantic_search()
        except Exception as e:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ RAG —Å–µ—Ä–≤–µ—Ä—É: {e}")
            logger.info("–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ RAG —Å–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω –Ω–∞ http://localhost:8000")
            logger.info("–ò —á—Ç–æ –≤ –±–∞–∑–µ –µ—Å—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã –¥–ª—è –ø–æ–∏—Å–∫–∞")
        
        logger.info("‚úÖ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏: {e}")

if __name__ == "__main__":
    asyncio.run(main()) 